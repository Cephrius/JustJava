Big O notaion 
"how code slows as data grows"

1. describes the performance of an algorithim as the amount of data increases
2. Machine independent (# of steps to completion)
3. Ignore smaller operations 0(n + 1) -> 0(n)

            examples:           n = amount of data 
            0(1)                (it's a variable like x)
            0(n)
            0(log n)
            0(n^2)


0(n) linear time

int addUp(int n){
    
    int sum = 0
    for(int i = 0; i <= n; i++) {
        sum += i
    }
    return sum
}

n = 1000000
~1000000 steps


0(1) constant time

int addUp(int n) {
    int sum = n * (n + 1) / 2;
    return sum;
}

0(1) = constant time
    - random access of an element in an array
    - inserting at the beginning of a linkedList

0(log n) = logarithmic time
    -  binary search

0(n) = linear time
    - looping through elemtns in an array
    - searching throught a linkedList

0(n log n) = quasilinear timen